import openai
import openpyxl
import pandas as pd
import argparse
from prompts_icl import icl_short_en_1
import time
import json
import re

from openai import OpenAI
from utils import extract_symp_from_df_label
from utils import extract_symp_from_df_icl
from utils import calculate_num_set
from utils import calculate_and_average_metrics
from utils import extract_sections
from utils import tokenize_numbering
from utils import mid_token_calc
from utils import mid_token_dist_calc

parser = argparse.ArgumentParser(
    description="Estimate Symptom and Section with In-Context Learning method"
)
parser.add_argument(
    "--data", help="Data File After Label Extraction with Excel Format", required=True
)
parser.add_argument(
    "--examplar",
    help="Examplar File for In-Context Learning with Excel Format",
    required=True,
)
parser.add_argument("--apikey", help="Your openai api key", required=True)
parser.add_argument(
    "--result", help="Filename of the output generated by GPT", required=True
)

args = parser.parse_args()
data_filename = args.data
examplar_file = args.examplar
api_key = args.apikey
gpt_result_filename = args.result


def create_icl_ex(df):

    prompts = []

    for _, row in df.iterrows():
        statement = row["Statement"]
        gt_label = row["Ground-truth label"]

        prompt = f"Input: {statement}\nOutput: {gt_label}"
        prompts.append(prompt)

    # Joining all the prompts together
    full_prompt = "\n\n".join(prompts)

    return full_prompt


def icl(df1, df2):

    # Add 'Estimation' Column
    df2["Estimation"] = ""

    client = openai.Client(api_key=api_key)

    model = "gpt-4"

    ignore = 0

    # Using enumerate to get an index (idx) and a value (statement) together
    for idx, statement in enumerate(df2["Statement"]):

        # Construct the full prompt
        full_prompt = create_icl_ex(df1)
        full_prompt += f"\n\nInput: {statement}"

        # Set up messages
        messages = icl_short_en_1
        messages[-1]["content"] += full_prompt

        response = openai.ChatCompletion.create(model=model, messages=messages)

        answer = response["choices"][0]["message"]["content"]
        df2["GPT-4 Output"].iloc[idx] = answer

    df2.to_excel(f"{gpt_result_filename}.xlsx", index=False)


# in-context learning
data = pd.read_excel(f"{data_filename}.xlsx")
examplar = pd.read_excel(f"{examplar_file}.xlsx")
icl(examplar, data)

# extract ground-truth symptoms
gpt_result = pd.read_excel(f"{gpt_result_filename}.xlsx")
extract_symp1 = extract_symp_from_df_label(gpt_result, "Ground-truth label", "Symptom")

# extract estimated symptoms
extract_symp2 = extract_symp_from_df_icl(
    extract_symp1, "Estimation", "Estimated Symptom"
)

# calcuate metrics used for multi-label classification in estimating symptoms
num_set_extract_symp2 = calculate_num_set(extract_symp2)
calculate_and_average_metrics(num_set_extract_symp2, icl_metric_symp)

# extract ground-truth sections and estimated sections
extract_sec = extract_sections(gpt_result)

# tokenize the text of ground-truth sections and estimated sections and number tokens of the text
tokenize_numbering(extract_sec, token_num_sec)

# calculate the mid-token of the ground-truth sections and estimated sections
mid_token_calc(token_num_sec, mid_token_calc_sec)

# calculate the recall mid-token distance
mid_token_dist_calc(mid_token_calc_sec, icl_midtoken)
